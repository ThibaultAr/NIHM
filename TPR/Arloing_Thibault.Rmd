---
title: "TP RMD"
subtitle: Arloing Thibault
output:
  pdf_document: default
  html_document: default
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library("gplots")
library("gmodels")
library("reshape")
library("ez")
```

##Premier Pas
```{r}
v = c(12, .4, 5, 2, 50, 8, 3, 1, 4, .25)
quantile(v, probs=c(0.9))
```

##Graphiques
```{r}
v = c(12, .4, 5, 2, 50, 8, 3, 1, 4, .25)
v2 = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)
boxplot(v, v2)
barplot(v, v2)
```

##Importation des donnÃ©es Ã  partir d'un fichiers
```{r}
data = read.table("data.txt", header=TRUE, sep=",")
participant2SurfPad=subset(data,Participant==2 & Technique=="SurfPad")
mean(participant2SurfPad[,"Time"])
```

###Q3
```{r}
moyTech = function(data, technique) {
  t = subset(data, Technique==technique)
  return(mean(t[,"Time"]))
}
```
Tests de fonctionnement
```{r}
moyTech(data, "SurfPad")
moyTech(data, "SemPoint")
```

###Q4
```{r}
techniques=unique(data$Technique)
moyTime = sapply(techniques, function(x)drop(moyTech(data, x)))
```

###Q5
```{r}
barplot(moyTime, names.arg = techniques, legend.text="Temps moyen")
```

###Q6
```{r}
dataWithoutErr = subset(data, Err!=1)
```

###Q7
```{r}
confianceInter = function(data, technique) {
  t = subset(data, Technique==technique)
  return(ci(t[,"Time"]))
}
```

###Q8
```{r}
moyTime = sapply(techniques, function(x)drop(moyTech(dataWithoutErr, x)))
confiance = sapply(techniques, function(x)drop(confianceInter(dataWithoutErr, x)))
ciLower = confiance["CI lower",]
ciUpper = confiance["CI upper",]
ciLower
ciUpper
```

```{r}
barplot2(moyTime, names.arg = techniques, legend.text = "Temps Moyen"
         , ci.l = ciLower, ci.u = ciUpper, plot.ci = TRUE)
```

##ANOVA
```{r}
# Chargement des donnees
data = read.table("data.txt", header=TRUE, sep=",")

# On ne garde que ce qui nous interesse
filteredData = subset(data, (Err==0), select = c(Participant, Block, Technique,
                      A, W, density, Time))

# Aggregation des donnees pour ne conserver quâ€™une valeur par condition
attach(filteredData)
aggdata = aggregate(filteredData$Time, by=list(Participant,Block,Technique,W, density),
                    FUN=mean)
detach(filteredData)

# Reecriture des noms de colonnes
colnames(aggdata) = c("Participant","Block","Technique","W", "density", "Time")

# Conversion des donnees au format long
data.long = melt(aggdata, id = c("Participant","Block","Technique","W","density","Time"))

# On specifie les variables independantes
data.long$Block = factor(data.long$Block)
data.long$Technique = factor(data.long$Technique)
data.long$W = factor(data.long$W)
data.long$density = factor(data.long$density)

# L'ANOVA:
print(ezANOVA(data.long, dv=.(Time), wid=.(Participant), within=.(Technique,W,density)))
```
Ici on peut voir dans les resultats de l'ANOVA (premier "paragraphe") que les trois première ligne correspondent aux effets principaux Technique, Density et W. Les lignes suivantes correspondent aux interactions entre les différents effets principaux.

La colonne **p** représente la probabilité pour que les résultats soient dues au hasard. Si **p** < 0.05, on considère que les tests réalisés par l'ANOVA ne sont pas dues au hasard et qu'il peuvent être significatives. La colonne **ges** correspond à l'impact statistique, c'est à dire la probabilité pour que l'expérience détecte cet effet. Une puissance supérieure à 0.80 signifie que l'effet existe vraiment.

Ici on peut donc voir que les résultats ne sont pas dues au hasard car **p** est inférieur à 0.5. Cependant, on ne peut considérer que l'effet existe vraiment car le **ges** est inférieur à 0.80.
On ne peut donc pas conclure qu'une technique est meilleure qu'une autre avec ces analyses.

```{r, include=FALSE}
# Analyse post-hoc avec ajustement de Bonferroni
attach(data.long)
print(pairwise.t.test(Time, interaction(Technique), p.adj = "bonf"))
print(pairwise.t.test(Time, interaction(Technique, density), p.adj = "bonf"))
detach(data.long)
```

###Q9

Comme expliqué ci-dessus, l'effet significatif de ***Technique*** ne permet donc pas de conclure que ***SurfPad*** est la meilleure technique. En effet, comme l'experience a été faite en intra-sujet, il faut étudier les intéractions entre les différentes techniques.

###Q10
```{r}
tempMoy = function(dataframe, dens, technique) {
  participants=subset(dataframe,Err==0 & Technique==technique & density==dens)
  return(mean(participants[,"Time"]))
}

tempMoyDens = function(dataframe, techniques, density) {
  return(sapply(techniques, tempMoy, dataframe=dataframe, dens=density))
}

techniques=unique(data$Technique)
densities=unique(data$density)

tmpMoyens = sapply(densities, tempMoyDens, dataframe=data, techniques=techniques)

barplot2(tmpMoyens, names.arg=densities, main="Temps moyens en fonction de la densité", xlab="Densité", ylab="Temps moyens", legend=techniques, xlim=c(0,30), beside=TRUE)

#Without SemPoint
dataWithoutSemPoint=subset(data, Technique!="SemPoint")
techniquesWithoutSemPoint=unique(dataWithoutSemPoint$Technique)

tmpMoyWithoutSemPoint = sapply(densities, tempMoyDens, dataframe=dataWithoutSemPoint, techniques=techniquesWithoutSemPoint)

barplot2(tmpMoyWithoutSemPoint, names.arg=densities, main="Temps moyens en fonction de la densité", xlab="Densité", ylab="Temps moyens", legend=techniquesWithoutSemPoint, xlim=c(0,24), beside=TRUE)
```

Ici on peut remarquer que le temps moyen pour la technique SemPoint augmente fortement avec le temps. 
Au contraire, lorsque l'on affiche le même graphe sans SemPoint, on voit que le temps moyen n'augmente plus de façon significative.
De plus, l'écart entre chaque technique reste quasimment constant. Dans ce cas, on peut considérer que la densité n'a plus d'impact sur les performances de chaque technique

On peut donc dire qu'en excluant les données de SemPoint, l'interaction entre Technique et Density n'existerait probablement plus.
